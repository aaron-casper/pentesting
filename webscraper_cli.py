#!/usr/bin/python
import urllib
import re
import sys

if len(sys.argv) == 1:
    print("==================================")
    print("a crappy web scraper, by floz")
    print("==================================")
    print("dumps a raw grab of the URL/URI\n")
    print("dumps it all out to stdout\n")
    print("then lists <P> and <A> elements\n")
    print("from the raw scrape.")
    print("==================================")
    print("usage:")
    print("webscraper.py [url] > [filename]\n")
    print("example:")
    print("webscraper.py http://google.com > google.txt")
    exit()

urlentered = sys.argv[1]

page = urllib.urlopen(urlentered)

contents = page.read()

content_array = contents.split('\n')

output = ""
print "-----------------\n"
print "RAW PAGE SCRAPE:\n"
print "-----------------\n"
for line in content_array:
    print line
    print "\n"
print "-----------------\n"
print "PARAGRAPHS FOUND:\n"
print "-----------------\n"
for line in content_array:
    paragraphs = re.findall(r'<p>(.*?)</p>',str(line))
    for eachP in paragraphs:
        print (eachP)
        print "\n"
print "-----------------\n"
print "LINKS FOUND:\n"
print "-----------------\n"

for line in content_array:
    links = re.findall(r'(?i)<a([^>]+)>(.+?)</a>',str(line))
    for eachP in links:
        urls = eachP
        for each in eachP:
            urldata = str(eachP)
            print urldata
            print "\n"
